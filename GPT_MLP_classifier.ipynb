{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/tomcio/Documents/GitHub/MIT_MBAn_NER/data/'\n",
    "data = pd.read_csv(path + 'training_data_RAW.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7918807810894142\n",
      "Precision: 0.29303845187232974\n",
      "Recall: 0.7319522912743252\n",
      "F1-score: 0.41852117731514715\n",
      "The word \"Aspirin\" is predicted to be a drug name with probability: 0\n",
      "The word \"Paracetamol\" is predicted to be a drug name with probability: 0\n",
      "The word \"Tromboner\" is predicted to be a drug name with probability: 0\n",
      "The word \"Rivaroxaban\" was found in the dataset and will be skipped.\n",
      "The word \"Icatibant\" was found in the dataset and will be skipped.\n",
      "The word \"Oxurion\" is predicted to be a drug name with probability: 0\n",
      "The word \"marta\" is predicted to be a drug name with probability: 0\n",
      "The word \"pupka\" is predicted to be a drug name with probability: 0\n",
      "The word \"schladming\" is predicted to be a drug name with probability: 1\n",
      "The word \"Sunshine\" was found in the dataset and will be skipped.\n",
      "The word \"Technology\" was found in the dataset and will be skipped.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a label encoder for all characters in the dataset\n",
    "all_characters = set(''.join(data['Name']))\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(list(all_characters))\n",
    "\n",
    "# Function to encode a word into a list of integers\n",
    "def encode_word(word):\n",
    "    return label_encoder.transform(list(word))\n",
    "\n",
    "# Encode all words in the dataset\n",
    "data['encoded'] = data['Name'].apply(lambda word: np.array(encode_word(word)))\n",
    "\n",
    "# Pad encoded sequences with zeros to ensure uniform length\n",
    "max_length = max(data['encoded'].apply(len))\n",
    "data['padded'] = data['encoded'].apply(lambda x: np.concatenate([x, np.zeros(max_length - len(x))]))\n",
    "\n",
    "# Prepare the dataset for training\n",
    "X = np.stack(data['padded'].values)\n",
    "y = data['label'].values\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Initialize and train the MLP classifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam', max_iter=500)\n",
    "mlp.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = mlp.predict(X_val)\n",
    "\n",
    "# Calculate and print various performance metrics\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "precision = precision_score(y_val, y_pred, average='binary')\n",
    "recall = recall_score(y_val, y_pred, average='binary')\n",
    "f1 = f1_score(y_val, y_pred, average='binary')\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-score: {f1}')\n",
    "\n",
    "# Function to make predictions on new words\n",
    "def predict_new_word(model, new_word):\n",
    "    encoded = np.array(encode_word(new_word))\n",
    "    padded = np.concatenate([encoded, np.zeros(max_length - len(encoded))])\n",
    "    prediction = model.predict([padded])\n",
    "    return prediction[0]\n",
    "\n",
    "# Example prediction\n",
    "new_word = \"Aspirin\"\n",
    "prediction = predict_new_word(mlp, new_word)\n",
    "print(f'The word \"{new_word}\" is predicted to be a drug name with probability: {prediction}')\n",
    "\n",
    "# Modified function to check if words are in the dataset before predicting\n",
    "def predict_and_print(words, model, data):\n",
    "    for word in words:\n",
    "        # Check if the word is in the dataset\n",
    "        if word.lower() in data['Name'].str.lower().values:\n",
    "            print(f'The word \"{word}\" was found in the dataset and will be skipped.')\n",
    "        else:\n",
    "            prediction = predict_new_word(model, word)\n",
    "            print(f'The word \"{word}\" is predicted to be a drug name with probability: {prediction}')\n",
    "\n",
    "\n",
    "# Additional words for prediction\n",
    "additional_words = [\n",
    "    \"Paracetamol\",  # Common medication\n",
    "    \"Tromboner\",    # Common medication\n",
    "    \"Rivaroxaban\",    # Common medication for diabetes\n",
    "    \"Icatibant\",  # Common medication for cholesterol\n",
    "    \"Oxurion\",   # Common medication for high blood pressure\n",
    "    \"marta\", # Antibiotic\n",
    "    \"pupka\",# Common in medication names but not a medication itself\n",
    "    \"schladming\",    # Not a medication\n",
    "    \"Sunshine\",     # Not a medication\n",
    "    \"Technology\"    # Not a medication\n",
    "]\n",
    "\n",
    "# Use the modified function with the additional_words list and the original dataset\n",
    "predict_and_print(additional_words, mlp, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Load the dataset\n",
    "path = '/Users/tomcio/Documents/GitHub/MIT_MBAn_NER/data/'\n",
    "data = pd.read_csv(path + 'training_data_RAW.csv')\n",
    "\n",
    "# Define a function to transform the dataset\n",
    "def transform_dataset(X):\n",
    "    return [' '.join(list(word)) for word in X]  # Separate characters by spaces\n",
    "\n",
    "# Initialize a pipeline with a custom transformer and TfidfVectorizer\n",
    "pipeline = make_pipeline(\n",
    "    FunctionTransformer(transform_dataset, validate=False),\n",
    "    TfidfVectorizer(analyzer='char', ngram_range=(1, 3)),\n",
    "    SVC(kernel='linear', class_weight='balanced', probability=True)\n",
    ")\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(data['Name'], data['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = pipeline.predict(X_val)\n",
    "\n",
    "# Calculate and print various performance metrics\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "precision = precision_score(y_val, y_pred, average='binary')\n",
    "recall = recall_score(y_val, y_pred, average='binary')\n",
    "f1 = f1_score(y_val, y_pred, average='binary')\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-score: {f1}')\n",
    "\n",
    "# Function to make predictions on new words\n",
    "def predict_new_word(model, new_word):\n",
    "    prediction = model.predict([new_word])[0]\n",
    "    probability = model.predict_proba([new_word])[0][prediction]\n",
    "    return prediction, probability\n",
    "\n",
    "# Test the model with new words\n",
    "test_words = [\"Aspirin\", \"Paracetamol\", \"Tromboner\", \"Oxurion\", \"marta\", \"pupka\", \"schladming\"]\n",
    "for word in test_words:\n",
    "    prediction, probability = predict_new_word(pipeline, word)\n",
    "    print(f'The word \"{word}\" is predicted to be a drug name with probability: {probability:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
